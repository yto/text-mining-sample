{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "plt.rcParams['font.family']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキストから単語共起ネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    '天皇は、日本国の象徴であり日本国民統合の象徴であって、この地位は、主権の存する日本国民の総意に基く。',\n",
    "    '皇位は、世襲のものであって、国会の議決した皇室典範の定めるところにより、これを継承する。',\n",
    "    '天皇の国事に関するすべての行為には、内閣の助言と承認を必要とし、内閣が、その責任を負う。',\n",
    "    '天皇は、この憲法の定める国事に関する行為のみを行い、国政に関する権能を有しない。',\n",
    "    '天皇は、法律の定めるところにより、その国事に関する行為を委任することができる。',\n",
    "    '皇室典範の定めるところにより摂政を置くときは、摂政は、天皇の名でその国事に関する行為を行う。',\n",
    "    'この場合には、前条第一項の規定を準用する。',\n",
    "    '天皇は、国会の指名に基いて、内閣総理大臣を任命する。',\n",
    "    '天皇は、内閣の指名に基いて、最高裁判所の長たる裁判官を任命する。',\n",
    "    '天皇は、内閣の助言と承認により、国民のために、左の国事に関する行為を行う。',\n",
    "    '憲法改正、法律、政令及び条約を公布すること。',\n",
    "    '国会を召集すること。',\n",
    "    '衆議院を解散すること。',\n",
    "    '国会議員の総選挙の施行を公示すること。',\n",
    "    '国務大臣及び法律の定めるその他の官吏の任免並びに全権委任状及び大使及び公使の信任状を認証すること。',\n",
    "    '大赦、特赦、減刑、刑の執行の免除及び復権を認証すること。',\n",
    "    '栄典を授与すること。',\n",
    "    '批准書及び法律の定めるその他の外交文書を認証すること。',\n",
    "    '外国の大使及び公使を接受すること。',\n",
    "    '儀式を行うこと。',\n",
    "    '皇室に財産を譲り渡し、又は皇室が、財産を譲り受け、若しくは賜与することは、国会の議決に基かなければならない。',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 形態素解析 janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "janome = Tokenizer()\n",
    "def ma_sentence(sentence):\n",
    "    return [{'surface': x.surface, 'pos': x.part_of_speech, 'base_form': x.base_form} for x in janome.tokenize(sentence)]\n",
    "\n",
    "ma_sentence('菓子を買ってもお金は減らず。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 形態素解析 MeCab\n",
    "import MeCab\n",
    "mecab = MeCab.Tagger('-Ochasen')\n",
    "def ma_sentence(sentence):\n",
    "    mors = [x.split('\\t') for x in mecab.parse(sentence).split('\\n')]\n",
    "    return [{'surface': mor[0], 'pos': mor[3], 'base_form': mor[2]} for mor in mors if len(mor) > 2]\n",
    "\n",
    "ma_sentence('菓子を買ってもお金は減らず。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mors_list = [ma_sentence(sentence) for sentence in sentences]\n",
    "print(mors_list[0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ワードのリストを作成\n",
    "import re\n",
    "words_list = [{mor['surface'] for mor in mors if re.match('^名詞(?!.*(代名詞|接尾|非自立))', mor['pos'])} for mors in mors_list]\n",
    "print(words_list[0])\n",
    "# ワードの頻度\n",
    "import collections\n",
    "all_words = [x for row in words_list  for x in row]\n",
    "ct_word = collections.Counter(all_words)\n",
    "print(ct_word.most_common()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ワードペアのリストを作成\n",
    "import itertools\n",
    "all_pairs = [tuple(sorted(x)) for row in [list(itertools.combinations(words, 2)) for words in words_list] for x in row]\n",
    "print(all_pairs[:5])\n",
    "# ワードペアの頻度\n",
    "ct_pair = collections.Counter(all_pairs)\n",
    "print(ct_pair.most_common()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフ表示に使うワードを限定する\n",
    "target_words = {x[0] for x in ct_word.most_common() if x[1] >= 1}\n",
    "print(list(target_words)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node と edge の　DataFrame を作る\n",
    "df_nodes = pd.DataFrame([\n",
    "    {'label': i[0], 'count': i[1]}\n",
    "    for i in ct_word.most_common() if i[0] in target_words\n",
    "])\n",
    "df_edges = pd.DataFrame([\n",
    "    {'node1': i[0][0], 'node2': i[0][1], 'count': i[1]}\n",
    "    for i in ct_pair.most_common() if i[0][0] in target_words and i[0][1] in target_words\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 頻度 (count) から weight を計算する\n",
    "# edge の　 weight は Jaccard 係数\n",
    "import math\n",
    "df_nodes['weight'] = df_nodes.apply(lambda x: math.log(x['count']), axis=1)\n",
    "df_edges['weight'] = df_edges.apply(lambda x: x['count'] / (ct_word[x['node1']] + ct_word[x['node2']] - x['count']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df_nodes.head(3), df_edges.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dictデータからネットワーク"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_edges = [\n",
    "    {'node1': '日本語', 'node2': '中国語', 'weight': 0.9},\n",
    "    {'node1': '英語', 'node2': '蘭語', 'weight': 0.9},\n",
    "    {'node1': '英語', 'node2': '仏語', 'weight': 0.7},\n",
    "    {'node1': '日本語', 'node2': '英語', 'weight': 0.6},\n",
    "    {'node1': '日本語', 'node2': '蘭語', 'weight': 0.5},\n",
    "    {'node1': '英語', 'node2': '中国語', 'weight': 0.2},\n",
    "    {'node1': '中国語', 'node2': '仏語', 'weight': 0.1},\n",
    "]\n",
    "data_nodes = [\n",
    "    {'label': '日本語', 'weight': 0.9},\n",
    "    {'label': '英語', 'weight': 0.7},\n",
    "    {'label': '中国語', 'weight': 0.5},\n",
    "    {'label': '仏語', 'weight': 0.2},  \n",
    "    {'label': '蘭語', 'weight': 0.1}, \n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_edges = pd.DataFrame(data_edges)\n",
    "df_nodes = pd.DataFrame(data_nodes)\n",
    "display(df_edges.head(3), df_nodes.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グラフの描画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "#G = nx.from_pandas_edgelist(df_edges, 'node1', 'node2', 'weight')\n",
    "G.add_edges_from(df_edges.apply(lambda x: (x['node1'], x['node2'], {'weight': x['weight']}), axis=1))\n",
    "G.add_nodes_from(df_nodes.apply(lambda x: (x['label'], {'weight': x['weight']}), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G, k=0.6, seed=0)\n",
    "width_list =[d['weight'] * 5 for (u, v, d) in G.edges(data=True)]\n",
    "node_size_list = [d['weight'] * 1000 + 500 for (n, d) in G.nodes(data=True)]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,10))\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_size_list, linewidths=2,\n",
    "                       # node_color=list(pr.values()), cmap=plt.cm.Reds,\n",
    "                       node_color='pink', alpha=0.5, ax=ax)\n",
    "nx.draw_networkx_edges(G, pos, width=width_list, edge_color='gray', alpha=0.1, ax=ax)\n",
    "nx.draw_networkx_labels(G, pos, font_size=12, font_color=\"black\", alpha=0.9, font_family=\"IPAGothic\", ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データと確認\n",
    "\n",
    "ラベルとテキストの2要素を持つ。\n",
    "テキストは日本語文であり、それを形態素解析して機械学習の素性とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## データをファイルから読み込む\n",
    "# 各行の例: ^Positive[\\t]これは素晴らしい。$\n",
    "#df_tmp = pd.read_csv('data/sample.tsv', sep='\\t', names=('Label', 'OriginalText'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## データを直接セットする\n",
    "df_tmp = pd.DataFrame([\n",
    "    {'Label': 'Positive', 'OriginalText': 'これは素晴らしい。'},\n",
    "    {'Label': 'Negative', 'OriginalText': '最悪の事態です。'},\n",
    "    {'Label': 'Other', 'OriginalText': 'お腹がすいた。'},\n",
    "    {'Label': 'Positive', 'OriginalText': '嬉しいことがあった'},\n",
    "    {'Label': 'Negative', 'OriginalText': 'こういうのはダメだと思う。'},\n",
    "    {'Label': 'Other', 'OriginalText': 'ペットボトルのお茶を飲みました。'},\n",
    "    {'Label': 'Positive', 'OriginalText': 'やったね！'},\n",
    "    {'Label': 'Negative', 'OriginalText': '悪い結果です。'},\n",
    "    {'Label': 'Other', 'OriginalText': '中性脂肪をやっつけろ！'},\n",
    "    {'Label': 'Positive', 'OriginalText': 'すごく良い。素晴らしき世界。'},\n",
    "    {'Label': 'Negative', 'OriginalText': '最低最悪の事態が発生しました'},\n",
    "    {'Label': 'Other', 'OriginalText': 'アーモンドとカシューナッツ、どっちにする？'},\n",
    "    {'Label': 'Positive', 'OriginalText': '大好きなお菓子を買えて嬉しい。'},\n",
    "    {'Label': 'Negative', 'OriginalText': 'こういうの絶対ダメ。ゆるされない。'},\n",
    "    {'Label': 'Other', 'OriginalText': '現在の時刻は午後3時30分です'},\n",
    "    {'Label': 'Positive', 'OriginalText': '最高です。とても良い結果です。'},\n",
    "    {'Label': 'Negative', 'OriginalText': 'ちょー最悪、ありえない'},\n",
    "    {'Label': 'Other', 'OriginalText': 'チャイムが鳴りました。'},\n",
    "    {'Label': 'Positive', 'OriginalText': '今日の天気は晴。久しぶりなので嬉しいな'},\n",
    "    {'Label': 'Negative', 'OriginalText': 'やめてくれよこういうの。最低。'},\n",
    "    {'Label': 'Other', 'OriginalText': '雨が降っています。'},\n",
    "    {'Label': 'Other', 'OriginalText': '夏は暑いが冬は寒い'},\n",
    "    {'Label': 'Other', 'OriginalText': 'ぬるいコーヒーを飲む。'},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルの分布の確認\n",
    "tmp = df_tmp['Label'].value_counts()\n",
    "print(tmp.to_dict())\n",
    "tmp.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テキストの処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストから余計な文字列を除去する処理\n",
    "def clean_sentence(sentence):\n",
    "    sentence = re.sub('https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+', '', sentence)\n",
    "    return sentence\n",
    "\n",
    "# テキストのクリーニング\n",
    "df_tmp['Text'] = df_tmp['OriginalText'].apply(clean_sentence)\n",
    "df_tmp.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 形態素解析 janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "janome = Tokenizer()\n",
    "def ma_sentence(sentence):\n",
    "    return [{'surface': x.surface, 'pos': x.part_of_speech, 'base_form': x.base_form} for x in janome.tokenize(sentence)]\n",
    "\n",
    "ma_sentence('菓子を買ってもお金は減らず。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 形態素解析 MeCab\n",
    "import MeCab\n",
    "mecab = MeCab.Tagger('-Ochasen')\n",
    "def ma_sentence(sentence):\n",
    "    mors = [x.split('\\t') for x in mecab.parse(sentence).split('\\n')]\n",
    "    return [{'surface': mor[0], 'pos': mor[3], 'base_form': mor[2]} for mor in mors if len(mor) > 2]\n",
    "\n",
    "ma_sentence('菓子を買ってもお金は減らず。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mor(sentences):\n",
    "    mors_list = [ma_sentence(x) for x in sentences]\n",
    "    chunked_sentences = []\n",
    "    for mors in mors_list:\n",
    "        ## 特定の品詞の形態素のみ使う\n",
    "        strs = [mor['base_form'] for mor in mors if re.match('名詞(?!.*(代名詞|接尾|非自立))|形容詞|動詞', mor['pos'])]\n",
    "        ## 前形態素を使う\n",
    "        #strs = [mor['surface'] for mor in mors]\n",
    "        chunked_sentences.append(\"\\t\".join(strs))\n",
    "    return chunked_sentences\n",
    "print(get_mor(['これは綺麗なペンです。','今日は歩きました'])) # => ['綺麗\\tペン', '今日\\t歩く']\n",
    "\n",
    "# テキストを単語分かち書きに\n",
    "chunks_train = get_mor(df_tmp['Text'])\n",
    "print(chunks_train[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 機械学習用の学習データへの変換 ベクトル化\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec_train = CountVectorizer(binary=True, ngram_range=(1,1), min_df=1, token_pattern='[^\\\\t]+')\n",
    "X_train = vec_train.fit_transform(chunks_train)\n",
    "vocabulary = vec_train.vocabulary_\n",
    "print(list(vocabulary.items())[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 文字ベース\n",
    "# 形態素解析を用いない場合はこちら\n",
    "\n",
    "# 機械学習用の学習データへの変換 ベクトル化\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec_train = CountVectorizer(binary=True, ngram_range=(2,2), min_df=1, token_pattern='.')\n",
    "X_train = vec_train.fit_transform(df_tmp['Text'])\n",
    "vocabulary = vec_train.vocabulary_\n",
    "print(list(vocabulary.items())[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_tmp['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0:2])\n",
    "print(\"------\")\n",
    "print(y_train[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2次元可視化\n",
    "\n",
    "可視化することで問題の難易度が分かるかもしれないし、分からないかもしれない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2次元に変換して図にする関数\n",
    "def kashika(X, y, X_len=[], random_state=0, n_SVD=2, sampling_rate=0.1):\n",
    "\n",
    "    # 可視化に使うデータをサンプリング\n",
    "    from sklearn.utils import shuffle\n",
    "    shuffled_index = shuffle(np.arange(0, len(y)), random_state=random_state)\n",
    "    mask = shuffled_index[:int(len(y)*sampling_rate)]\n",
    "    X_sample = X[mask]\n",
    "    \n",
    "    # 2次元に変換\n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    deco_model = TruncatedSVD(n_components=n_SVD)\n",
    "    proj = deco_model.fit_transform(X_sample)\n",
    "    \n",
    "    # 描画\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    sns.scatterplot(proj[:,0], proj[:,1],\n",
    "                    hue=y[mask],\n",
    "                    alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = kashika(X_train, y_train, sampling_rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習と精度確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import (cross_val_score, cross_val_predict, KFold)\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(logistic, X_train, y_train, cv=KFold(n_splits=2, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(conf_mat.T, square=True, annot=True, fmt='d', cbar=False, cmap='RdPu',\n",
    "            xticklabels=np.unique(y_train), yticklabels=np.unique(y_train))\n",
    "ax.set_ylim(len(conf_mat), 0) # for matplotlib 3.1.1 以下。3.1.2以降は不要\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))\n",
    "clarep = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True)).T\n",
    "clarep['support'] = clarep['support'].astype(int)\n",
    "display(clarep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 個別判定結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp['Pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正しく判定できた例\n",
    "df_tmp[df_tmp['Label'] == df_tmp['Pred']][['Label','Pred','OriginalText']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正しく判定できなかった例\n",
    "df_tmp[df_tmp['Label'] != df_tmp['Pred']][['Label','Pred','OriginalText']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 判定に寄与する素性の確認"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C' : [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(solver='lbfgs', multi_class='auto'), param_grid, cv=2)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_score_, grid.best_params_)\n",
    "fdf = pd.DataFrame(grid.best_estimator_.coef_.T, columns=grid.best_estimator_.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traall = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto')\n",
    "traall.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame(traall.coef_.T, columns=traall.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fdf['vocabulary'] = vec_train.get_feature_names_out()\n",
    "fdf['vocabulary'] = vec_train.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranking = pd.DataFrame()\n",
    "for c in traall.classes_:\n",
    "    p = fdf.sort_values([c], ascending=False)[[c, 'vocabulary']]\n",
    "    p.index = np.arange(len(p))\n",
    "    feature_ranking = pd.concat([feature_ranking, p], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranking[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
